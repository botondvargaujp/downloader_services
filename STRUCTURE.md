# ğŸ“ Repository Structure

## Overview
Clean, organized structure for multiple football data downloader services.

## Directory Structure

```
downloader_services/
â”‚
â”œâ”€â”€ transferroom_service/          # TransferRoom API integration
â”‚   â”œâ”€â”€ ingest_pipeline.py        # Main ingestion pipeline (800 lines)
â”‚   â””â”€â”€ env.template               # Configuration template
â”‚
â”œâ”€â”€ database/                      # Database schemas
â”‚   â””â”€â”€ db_schema.sql             # PostgreSQL schema (6 tables, 40+ indexes)
â”‚
â”œâ”€â”€ data/                          # Source data files
â”‚   â””â”€â”€ competitions.json         # Competition reference data
â”‚
â”œâ”€â”€ docs/                          # Complete documentation (2,500+ lines)
â”‚   â”œâ”€â”€ DATABASE_README.md        # Setup and usage guide
â”‚   â”œâ”€â”€ PIPELINE_ARCHITECTURE.md  # System architecture
â”‚   â”œâ”€â”€ FINAL_SUCCESS_REPORT.md   # Latest status report
â”‚   â””â”€â”€ ... (8 more docs)
â”‚
â”œâ”€â”€ exports/                       # Data exports and analysis
â”‚   â”œâ”€â”€ competition_ratings.xlsx  # Competition analysis
â”‚   â””â”€â”€ process_competitions.py   # Export script
â”‚
â”œâ”€â”€ tmroom_legacy/                # Legacy scripts (reference only)
â”‚   â”œâ”€â”€ tmroom_api_testing.py    # Old testing script
â”‚   â”œâ”€â”€ test_comps.py            # Old test
â”‚   â””â”€â”€ main.py                   # Old main
â”‚
â”œâ”€â”€ pyproject.toml                # Python project config (uv)
â”œâ”€â”€ requirements.txt              # Pip requirements
â”œâ”€â”€ uv.lock                       # Dependency lock
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ README.md                     # Main documentation
```

## Service Organization

### Active Services
1. **transferroom_service/** - TransferRoom API downloader
   - Status: âœ… Operational
   - Data: ~190K players, 357 competitions
   - Features: Batch processing, progress tracking, error handling

### Future Services
2. **[datasource2]_service/** - Template for next data source
   - Follow same pattern as transferroom_service
   - Each service is independent and self-contained

## File Purposes

### Core Application Files
- `transferroom_service/ingest_pipeline.py` - Main data ingestion script
- `transferroom_service/env.template` - Environment configuration template
- `database/db_schema.sql` - Complete PostgreSQL database schema

### Configuration Files
- `pyproject.toml` - Project dependencies and metadata (uv package manager)
- `requirements.txt` - Alternative pip requirements
- `.gitignore` - Files to exclude from git
- `README.md` - Main project documentation

### Data Files
- `data/competitions.json` - Source competition data (357 competitions)
- `exports/` - Generated analysis files (not in git)

### Documentation
- `docs/DATABASE_README.md` - Database setup and queries
- `docs/PIPELINE_ARCHITECTURE.md` - System design and architecture
- `docs/FINAL_SUCCESS_REPORT.md` - Latest test results and status
- `docs/PLAYER_INGESTION_GUIDE.md` - Usage instructions
- Plus 7 more detailed guides

### Legacy (Reference Only)
- `tmroom_legacy/` - Old scripts kept for reference
- Not used in production

## Key Features

### Clean Separation
âœ… Each data source has its own service directory  
âœ… Shared database schema in central location  
âœ… Documentation separate from code  
âœ… Legacy code isolated  

### Scalability
âœ… Easy to add new data sources  
âœ… Independent service deployments  
âœ… Shared database infrastructure  
âœ… Centralized documentation  

### Maintainability
âœ… Clear file organization  
âœ… Self-documenting structure  
âœ… Consistent patterns  
âœ… Version controlled  

## Quick Navigation

**Need to...**
- Start ingesting data? â†’ `transferroom_service/ingest_pipeline.py`
- Setup database? â†’ `database/db_schema.sql`
- Configure environment? â†’ `transferroom_service/env.template`
- Read documentation? â†’ `docs/`
- Add new data source? â†’ Create new `[source]_service/` directory
- Analyze data? â†’ `exports/`
- Reference old code? â†’ `tmroom_legacy/`

## Commands by Directory

### From Root
```bash
# Setup
createdb transferroom
psql -d transferroom -f database/db_schema.sql

# Run ingestion
uv run transferroom_service/ingest_pipeline.py --test
```

### TransferRoom Service
```bash
cd transferroom_service
uv run ingest_pipeline.py --players-only --max-players 10000
```

### Database
```bash
cd database
psql -d transferroom -f db_schema.sql
```

### Exports
```bash
cd exports
python process_competitions.py
```

## Adding New Data Source

1. **Create service directory:**
```bash
mkdir new_datasource_service
cd new_datasource_service
```

2. **Create files:**
```
new_datasource_service/
â”œâ”€â”€ ingest_pipeline.py    # Copy and adapt from transferroom_service
â”œâ”€â”€ env.template          # Add new source credentials
â””â”€â”€ README.md            # Document the new source
```

3. **Update main README** with new service info

4. **Update database schema** if needed (add tables in `database/`)

## Size Information

```
Database Schema:    ~20 KB (400 lines SQL)
Python Pipeline:    ~40 KB (800 lines)
Documentation:      ~150 KB (2,500+ lines)
Data Files:        ~200 KB (competitions.json)
Total (no data):   ~500 KB
With 190K players: ~1 GB
```

## Clean Architecture Benefits

âœ… **Easy to understand** - Clear directory names
âœ… **Easy to extend** - Add new services without conflicts  
âœ… **Easy to maintain** - Find files quickly  
âœ… **Easy to deploy** - Independent services  
âœ… **Easy to document** - Centralized docs  
âœ… **Easy to test** - Isolated components  

---

**Structure Status**: âœ… Clean and Production Ready
